# Regression

## What's Machine Learning ?

Looking for Function

我们需要去拟合得到很多不同的函数（映射）

接收各种信息，得到我们想要的

* 如果我们得到的是一个 scalar ，这样的过程叫做 regression 
* 如果我们得到的是一个从多个选项中找出的一个选项，这样的过程叫做 classification
* 如果我们得到的是一个有结构的text或者image等一系列的内容，那我们把这个过程叫做 Structured Learning

## Different Kinds of Machine Learning

### Supervised Learning

通过大量的资料训练，让机器得到一个范式，可以根据已有信息推测出未知信息的结果。

### Self-supervised Learning

我们希望机器通过材料自动学习

#### Pre-train Model

Develop general purpose knowledge

我们期待机器通过 Pre-train ，得到通用的本领，可以适用于普遍目标

用大量的 unlabeled images 去对其进行训练，提高效率（用 unlabeled images 去训练有很强的特殊性，后续会具体讲解）

主要的训练方式就是用不同方向或者不同色调的同一张图片给机器训练，让其在接触问题之前触及问题的本质

#### Downstream Tasks

我们实际进行的具体训练，与 Supervised Learning 类似

### Generative Adversarial Network

我们另一种让机器自动学习的方法

在 Self-supervised Learning 中，我们是对信息源进行特殊训练，让模型针对性比较强，而我们的另一种方式是通过并不 pair 的数据让机器自然具有 pair 的能力

### Reinforcement Learning(RL)

当我们无法判断做出的选择是否正确，我们仅仅可以判断最终结果的时候，我们应该使用，这种方法

### 拓展议题1：Anomaly Detection

让机器对对自己领域外的内容进行报错

### 拓展议题2：Explainable AI

让ai告诉你给出答案的理由

### 拓展议题3：Model Attack

模型会因为小漏洞而出现被攻击的情况，做出错误的判断。以及面对攻击我们如何防御

### 拓展议题4：Domain Adaptation

当训练的材料和实际测试的材料都模式不同时，如何保持高正确率

### 拓展议题5：Network Compression

如何让较大的模型变小，将其压缩

### 拓展议题6：Life-long Learning

为何我们现在无法让机器不断的学习

### Meta Learning

Learn How to Learn

我们想要机器从已知的我们找到的各种映射，找到一种通用的范式，能够自行找到一种学习的方式从学习方式中找寻新的学习方式

Meta Learning 明显的与 Life-long Learning 有关联，也与 Few-shot Learning 相关

## One Example

我们现在的问题是预测未来一天的YouTube某个频道的播放量，既然我们现在一无所有，那么就从 Supervised Learning 开始。

我们期望每一天的播放数据都与以前的数据相关，这是我们能够解决这个问题的前提，尽管没有任何社会学的研究说明这之间有关联，但是我们总是如此相信，不然我们就无法进行这个预测。（人类的智能也是这样的，我们把我们猜测的东西当作真理，然后再逐渐去理清楚什么是真的什么是假的，更具体的来说我们通过不断的求证去改良我们的直觉，让它更加接近真实。机器学习也是训练机器的直觉，越深层的机器学习就是越深层的直觉，让其更清晰的知道为什么这是对的这是错的，提高其认知）

我们现在手头拥有的资料，是过去一年时间内每天这个频道的播放量。我们注意到这个问题是一个 scalar-to-scalar 的问题，我们实际上就是为了找到一个数学意义上的函数。这个函数显然非常非常的复杂，但同时我们并不需要具体知道这个函数的组成，我们需要的是找到一个近似的函数去得到近似的结果。因此，虽然在课程中李老师以线性的函数来开头，但作为听完课我们应该知道，由于我们可以使用很多个线性函数去组合起来拟合复杂函数，我们才会想到用多个 Sigmoid。对于我们现在的 scalar-to-scalar 的问题，我们有两个 Sigmoid 可以使用，分别是soft和hard

$\begin{align*}
  & y=c\frac{1}{1+e^{-(b+wx_1)}}\newline& y=c\max(0,b+wx_1)
\end{align*}$

（我的 latex 排版很烂）

我们把第二个Sigmoid 叫做 Rectified Linear Unit（ReLU）

我们自然可以用这两种 Sigmoid 来逼近我们需要的函数，但我们还需要遵循下面三个 steps 让其成为现实

### 构建一个模型

我们将多个 Sigmoid 组合在一起，使其变得更 fat 或者更 deep，我们在后续再讨论 fat 和 deep 分别对模型有什么影响

### 定义Loss

我们给出的模型中有大量的未知常数（叫做parameters），我们需要定义一个关于所有未知常数的函数 Loss，Loss表示了我们模型在这个参数下与实际结果的差距，在高中我们就知道，这样的 Loss 有两种方式描述：absolute error 和 square error

$& e=\left\vert y-\hat{y} \right\vert\newline & e=(y-\hat{y})^2$

整体的 Loss 用这些的平均值来描述，我们根据一点微积分的知识，就知道，Loss是描述我们给出的参数优劣的多元函数，在某一个点的导数实际上对应一个空间而且这个空间是平的，这个性质对于我们下一个步骤很有用

### 最优化

当我们定义了 Loss 函数之后，我们显然是想要得到一个 Loss 最小的 parameters。实际我们无法从一个过于复杂的函数很容易得到其最值。我们最好借助很多的算法。

其中一个普适性的 Optimization 算法是 Gradient Descent（爬山算法），这个算法的核心在于不断松弛，从一个不太优秀的点出发，计算其导数，通过导数得到下一个更优秀的点，以此往复，找到一个最优点。这个做法的缺点很明显，在面对多峰函数时，很有可能我们会最终停留在另一个极值点，而非最值点。（关于如何改善，我现在考虑到的是多次模拟退火）

### 总结

整体上面的三个过程就叫做 training ，training的效果就是获得了一个拟合函数，正如课程中一开始用线性函数一样，我们想要用一些办法让拟合的精度更高。

三个 steps 是相互独立的，那么三个 steps 分别的优化都可以优化我们的拟合效果。

对于模型我们可以增加模型的宽度进行更广泛的采样，也可以增加模型的深度进行更为抽象的采样。

对于 Loss 函数，我们可以通过不同的权重（也就是空间上每个方向的步长）使得优化更为合理

对于 Optimization 过程，我们可以考虑有什么方法可以让其快速逼近，有什么办法可以让其不被困在局部最优解，这些都是很好的思路。

### 遗留问题

虽然理论上来讲我们只需要不断的增加深度和宽度，得到的函数就会在我们给出的训练数据表现越来越好。但是当我们超出一个范围时，会发现即使其在训练数据中表现较好，但是在未测试数据中表现越来越差。实际使用中，我们很多时候更关心在未测试数据中的效果。这种现象叫做过拟合（Overfitting）。

就像我们自己在学习过程中也要留有一点思考的余地，了解事物的本质，而不是死记硬背，当遇到新的内容时接受力就会很差。

这个问题将在后面提到，这也是 deep 比 fat 更优秀的点。